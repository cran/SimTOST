<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Introduction</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>






<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction</h1>



<p>In the <code>SimTOST</code> R package, which is specifically designed
for sample size estimation for bioequivalence studies, hypothesis
testing is based on the Two One-Sided Tests (TOST) procedure. <span class="citation">(<a href="#ref-sozu_sample_2015">Sozu et al.
2015b</a>)</span> In TOST, the equivalence test is framed as a
comparison between the the null hypothesis of ‘new product is worse by a
clinically relevant quantity’ and the alternative hypothesis of
‘difference between products is too small to be clinically
relevant’.</p>
<div id="hypotheses" class="section level1">
<h1>Hypotheses</h1>
<p>The null and alternative hypotheses for the equivalence test are
presented below for two different approaches:</p>
<div id="difference-of-means-dom" class="section level2">
<h2>Difference of Means (DOM)</h2>
<p>One common approach for assessing bio-equivalence involves comparing
pharmacokinetic (PK) measures between test and reference products. This
is done using the following interval (null) hypothesis:</p>
<p>Null Hypothesis (<span class="math inline">\(H_0\)</span>): At least
one endpoint does not meet the equivalence criteria:</p>
<p><span class="math display">\[H_0: m_T^{(j)} - m_R^{(j)} \le \delta_L
~~ \text{or}~~ m_T^{(j)} - m_R^{(j)} \ge \delta_U \quad \text{for at
least one}\;j\]</span></p>
<p>Alternative Hypothesis (<span class="math inline">\(H_1\)</span>):
All endpoints meet the equivalence criteria:</p>
<p><span class="math display">\[H_1: \delta_L&lt;m_{T}^{(j)}-m_{R}^{(j)}
&lt;\delta_U \quad\text{for all}\;j\]</span></p>
<p>Here, <span class="math inline">\(m_T\)</span> and <span class="math inline">\(m_R\)</span> represent the mean endpoints for the
test product (the proposed biosimilar) and the reference product,
respectively. The equivalence limits, <span class="math inline">\(\delta_L\)</span> and <span class="math inline">\(\delta_u\)</span>, are typically chosen to be
symmetric, such that <span class="math inline">\(\delta = - \delta_L =
\delta_U\)</span>.</p>
<p>The null hypothesis (<span class="math inline">\(H_0\)</span>) is
rejected if, and only if, all null hypotheses associated with the <span class="math inline">\(K\)</span> primary endpoints are rejected at a
significance level of <span class="math inline">\(\alpha\)</span>. This
ensures that equivalence is established across all endpoints
simultaneously.</p>
<p>The DOM test can be implemented in <a href="../reference/sampleSize.html">sampleSize()</a> by setting
<code>ctype = &quot;DOM&quot;</code> and <code>lognorm = FALSE</code>.</p>
<p>For pharmacokinetic (PK) outcomes, such as the area under the curve
(AUC) and maximum concentration (Cmax), log-transformation is commonly
applied to achieve normality. To perform this transformation, the
logarithm of the geometric mean should be provided to
<code>mu_list</code>, while the logarithmic variance can be derived from
the coefficient of variation (CV) using the formula:</p>
<p><span class="math display">\[
\text{Logarithmic Variance} = \log\left(1 + {\text{CV}^2}\right)
\]</span></p>
<p>Equivalence limits must also be specified on the log scale to align
with the transformed data.</p>
</div>
<div id="ratio-of-means-rom" class="section level2">
<h2>Ratio of Means (ROM)</h2>
<p>The equivalence hypotheses can also be expressed as a Ratio of Means
(ROM):</p>
<p>Null Hypothesis (<span class="math inline">\(H_0\)</span>): At least
one endpoint does not meet the equivalence criteria:</p>
<p><span class="math display">\[H_0: \frac{\mu_T^{(j)}}{\mu_R^{(j)}} \le
E_L ~~ \text{or}~~ \frac{\mu_T^{(j)}}{\mu_R^{(j)}} \ge E_U \quad
\text{for at least one}\;j\]</span></p>
<p>Alternative Hypothesis (<span class="math inline">\(H_1\)</span>):
All endpoints meet the equivalence criteria:</p>
<p><span class="math display">\[H_1: E_L&lt;
\frac{\mu_{T}^{(j)}}{\mu_{R}^{(j)}} &lt; E_U \quad\text{for
all}\;j\]</span></p>
<p>Here, <span class="math inline">\(\mu_T\)</span> and <span class="math inline">\(\mu_R\)</span> represent the arithmetic mean
endpoints for the test product (the proposed biosimilar) and the
reference product, respectively.</p>
<p>The ROM test can be implemented in <a href="../reference/sampleSize.html">sampleSize()</a> by setting
<code>ctype = &quot;ROM&quot;</code> and <code>lognorm = TRUE</code>. Note that
the <code>mu_list</code> argument should contain the arithmetic means of
the endpoints, while <code>sigma_list</code> should contain their
corresponding variances.</p>
<p>The ROM test is converted to a Difference of Means (DOM) tests by
log-transforming the data and equivalence limits. The variance on the
log scale is calculated using the normalized variance formula:</p>
<p><span class="math display">\[
\text{Logarithmic Variance} = \log\left(1 + \frac{\text{Arithmetic
Variance}}{\text{Arithmetic Mean}^2}\right)
\]</span></p>
<p>The logarithmic mean is then calculated as:</p>
<p><span class="math display">\[\text{Logarithmic Mean} =
\log(\text{Arithmetic Mean}) - \frac{1}{2}(\text{Logarithmic
Variance})\]</span></p>
</div>
<div id="regulatory-requirements" class="section level2">
<h2>Regulatory Requirements</h2>
<p>When evaluating bioequivalence, certain statistical and
methodological requirements must be adhered to, as outlined in the
European Medicines Agency’s bioequivalence guidelines <span class="citation">(<a href="#ref-CHMP2010">Committee for Medicinal
Products for Human Use (CHMP) 2010</a>)</span>. These requirements
ensure that the test and reference products meet predefined criteria for
equivalence in terms of PK parameters. The key considerations are
summarized below:</p>
<ul>
<li>Hypothesis testing should be based on the ratio of the population
geometric means</li>
<li>The 90% confidence interval for the ratio of the test and reference
products should be contained within the acceptance interval of 80.00 to
125.00%.</li>
<li>A margin of clinical equivalence (<span class="math inline">\(\Delta\)</span>) is chosen by defining the largest
difference that is clinically acceptable, so that a difference larger
than this would matter in practice.</li>
<li>The data should be transformed prior to analysis using a logarithmic
transformation and subsequently be analyzed using ANOVA</li>
</ul>
<p>When conducting a DOM test, The FDA recommends that the equivalence
acceptance criterion (EAC) be defined as <span class="math inline">\(\delta = EAC = 1.5 \sigma_R\)</span>, where <span class="math inline">\(\sigma_R\)</span> represents the variability of
the log-transformed endpoint for the reference product.</p>
</div>
</div>
<div id="testing-of-multiple-endpoints" class="section level1">
<h1>Testing of multiple endpoints</h1>
<p>Assessment of equivalence is often required for more than one primary
variable. <span class="citation">(<a href="#ref-sozu_sample_2015">Sozu
et al. 2015b</a>)</span> For example, EMA recommends showing equivalence
both for AUC and Cmax</p>
<p>A decision must be made as to whether it is desirable to</p>
<ul>
<li>Demonstrate equivalence for all primary endpoints
<ul>
<li>This is the most common setting and is often referred to as having
<em>multiple co-primary endpoints</em>.</li>
<li>Equivalence must be demonstrated for <strong>all</strong> endpoints
to conclude overall equivalence.</li>
</ul></li>
<li>Demonstrate equivalence for at least one of the primary endpoints
<ul>
<li>Known as having <em>multiple primary endpoints</em>.</li>
<li>Equivalence is required for <strong>at least one</strong> endpoint
to meet the study’s objectives.</li>
</ul></li>
</ul>
<div id="testing-multiple-co-primary-endpoints" class="section level2">
<h2>Testing multiple co-primary endpoints</h2>
<p>When a trial defines multiple co-primary endpoints, equivalence must
be demonstrated for all of them to claim overall treatment equivalence.
In this setting, each endpoint is tested separately at the usual
significance level (<span class="math inline">\(\alpha\)</span>), and
equivalence is established only if all individual tests are
statistically significant. Because conclusions require rejecting all
null hypotheses, a formal multiplicity adjustment is not needed to
control the Type I error rate. <span class="citation">(<a href="#ref-cpmp_points_2002">Committee for Propietary Medicinal Products
(CPMP) 2002</a>)</span> However, as the number of co-primary endpoints
(<span class="math inline">\(K\)</span>) increases, the likelihood of
failing to meet equivalence on at least one endpoint also rises,
resulting in a higher Type II error rate (i.e., a greater risk of
incorrectly concluding non-equivalence) <span class="citation">(<a href="#ref-mielke_sample_2018">Mielke et al. 2018</a>)</span></p>
<p>This has several important implications:</p>
<ul>
<li><strong>Reduced Power in Rare Diseases</strong>. Previous studies
have shown that the sample size required to maintain a given power level
increases as the number of endpoints increases. <span class="citation">(<a href="#ref-mielke_sample_2018">Mielke et al.
2018</a>)</span> This effect is particularly pronounced when the test
statistics are uncorrelated or when a large number of tests are
performed. In common conditions, this loss of power can often be
compensated by increasing the sample size. In rare diseases, however,
patient recruitment is often limited, making it more challenging to
achieve equivalence across all endpoints and increasing the risk of an
inconclusive result.</li>
<li><strong>Alternative Statistical Approaches</strong>. To address
power loss from requiring equivalence across multiple endpoints,
alternative methods have been proposed. For example, one option is to
power the study so that equivalence can be demonstrated for at least
<span class="math inline">\(k\)</span> tests, rather than requiring all
endpoints to meet the equivalence criterion. Another approach is
hierarchical testing, where endpoints are tested sequentially based on
predefined rules, allowing for partial conclusions when equivalence is
demonstrated in a subset of endpoints. See <a href="#multiple-primary">Testing multiple primary endpoints</a> for more
details.</li>
<li><strong>Regulatory Considerations</strong>. Regulatory agencies
often require a pre-specified statistical strategy to handle multiple
endpoints in equivalence trials. Without proper planning, the risk of
failing to establish equivalence in all endpoints may lead to
inconclusive results, even if the treatments are meaningfully
similar.</li>
</ul>
</div>
<div id="multiple-primary" class="section level2">
<h2>Testing multiple primary endpoints</h2>
<p>When a trial aims to establish equivalence for at least <span class="math inline">\(k\)</span> primary endpoints, adjustments are
necessary to account for the increased risk of Type I error due to
multiple hypothesis testing <span class="citation">(<a href="#ref-sozu_continuous_2015">Sozu et al. 2015a</a>)</span>. Without
such adjustments, the likelihood of incorrectly concluding equivalence
for at least one endpoint increases as the number of endpoints
grows.</p>
<p>For example, if a study includes <span class="math inline">\(m =
3\)</span> independent primary endpoints and uses a significance level
of <span class="math inline">\(\alpha = 5%\)</span> for each test, the
overall probability of falsely concluding equivalence for at least one
endpoint is:</p>
<p><span class="math display">\[ 1 – (1-\alpha)^m  = 1 - (1-0.05)^3 =
0.1426. \]</span> This means that the overall probability of making any
false positive error, also known as the <strong>family-wise error rate
(FWER)</strong>, increases to approximately 14%.</p>
<p>To address this issue, adjustments to the significance level are
necessary for multiple endpoint comparisons for which various methods
have been proposed. In SimTOST, the following approaches are
included:</p>
<div id="bonferroni-correction" class="section level3">
<h3>Bonferroni correction</h3>
<p>The most common and easiest procedure for multiplicity adjustment to
control the FWER is the Bonferroni method. Each hypothesis is tested at
level</p>
<p><span class="math display">\[\alpha_{bon}= \alpha/m\]</span></p>
<p>where <span class="math inline">\(m\)</span> is the total number of
tests. Although simple, this method is highly conservative, particularly
when tests are correlated, as it assumes all tests are independent. This
conservativeness remains pronounced even for <span class="math inline">\(k=1\)</span>, where only one of the <span class="math inline">\(m\)</span> hypotheses needs to be rejected. <span class="citation">(<a href="#ref-mielke_sample_2018">Mielke et al.
2018</a>)</span></p>
<p>In the <a href="../reference/sampleSize.html">sampleSize()</a>
function, the Bonferroni correction can be applied by setting
<code>adjust = &quot;bon&quot;</code>.</p>
</div>
<div id="sidak-correction" class="section level3">
<h3>Sidak correction</h3>
<p>The Sidak correction is an alternative method for controlling the
FWER. Like the Bonferroni correction, it assumes that tests are
independent. However, the Sidak correction accounts for the joint
probability of all tests being non-significant, making it mathematically
less conservative than the Bonferroni method. The adjusted significance
level is calculated as:</p>
<p><span class="math display">\[\alpha_{sid}= 1-(1-\alpha)^
{1/m}\]</span></p>
<p>The Sidak correction can be implemented by specifying
<code>adjust = &quot;sid&quot;</code> in the <a href="../reference/sampleSize.html">sampleSize()</a> function.</p>
</div>
<div id="k-adjustment" class="section level3">
<h3>K adjustment</h3>
<p>This correction explicitly accounts for the scenario where
equivalence is required for only <span class="math inline">\(k\)</span>
out of <span class="math inline">\(m\)</span> endpoints. Unlike the
Bonferroni and Sidak corrections, which assume that all <span class="math inline">\(m\)</span> tests contribute equally to the overall
Type I error rate, the <em>k</em>-adjustment directly incorporates the
number of endpoints (<span class="math inline">\(k\)</span>) required
for equivalence into the adjustment. The adjusted significance level is
calculated as:</p>
<p><span class="math display">\[\alpha_k=
\frac{k*\alpha}{m}\]</span></p>
<p>where <span class="math inline">\(k\)</span> is the number of
endpoints required for equivalence, and <span class="math inline">\(m\)</span> is the total number of endpoints
evaluated.</p>
</div>
</div>
<div id="hierarchical-testing-of-multiple-endpoints" class="section level2">
<h2>Hierarchical testing of multiple endpoints</h2>
<p>Hierarchical testing is an approach to multiple endpoint testing
where endpoints are tested in a predefined order, typically based on
their clinical or regulatory importance. A fallback testing strategy is
applied, allowing sequential hypothesis testing. If a hypothesis earlier
in the sequence fails to be rejected, testing stops, and subsequent
hypotheses are not evaluated. <span class="citation">(<a href="#ref-chowdhry_finding_2024">Chowdhry et al. 2024</a>)</span></p>
<p>To implement hierarchical testing in <code>simTOST</code>, the user
specifies <code>adjust = &quot;seq&quot;</code> in the <a href="../reference/sampleSize.html">sampleSize()</a> function and
defines primary and secondary endpoints using the <code>type_y</code>
vector argument. The significance level (<span class="math inline">\(\alpha\)</span>) is adjusted separately for each
group of endpoints, ensuring strong control of the Family-Wise Error
Rate (FWER) while maintaining interpretability.</p>
<ol style="list-style-type: decimal">
<li><strong>Evaluate (co-)primary endpoints</strong>
<ul>
<li>Testing begins with the pre-specified (co-)primary endpoints at the
nominal significance level.</li>
<li>Equivalence must be demonstrated for <em>all</em> (co-)primary
endpoints.</li>
<li>If any primary endpoint fails to meet the equivalence criteria,
testing stops, and secondary endpoints are not evaluated.</li>
</ul></li>
<li><strong>Proceed to secondary endpoints (if applicable)</strong>
<ul>
<li>If all primary endpoints meet the equivalence criteria, testing
proceeds to the secondary endpoints.</li>
<li>Equivalence must be demonstrated for at least <code>k</code>
secondary endpoints.</li>
<li>The significance level for secondary endpoints is adjusted using
k-adjustment.</li>
</ul></li>
<li><strong>Final Decision</strong>
<ul>
<li>The test is considered successful if <em>all</em> (co-)primary
endpoints meet the equivalence criteria and at least <code>k</code>
secondary endpoints demonstrate equivalence.</li>
</ul></li>
</ol>
<p>An example of hierarchical testing can be found in <a href="sampleSize_parallel_2A3E.html#hierarchical-testing">this
vignette</a>.</p>
</div>
</div>
<div id="testing-of-multiple-treatments" class="section level1">
<h1>Testing of multiple treatments</h1>
<p>In certain cases, it may be necessary to compare multiple treatments
simultaneously. This can be achieved by specifying multiple comparators
in the <code>mu_list</code> and <code>sigma_list</code> parameters. The
<a href="../reference/sampleSize.html">sampleSize()</a> function can
accommodate multiple treatments, allowing for the evaluation of
equivalence across different products or formulations.</p>
<p>Although trials with multiple arms are common, there is no clear
consensus in the literature as to whether statistical corrections should
be applied for testing multiple primary hypotheses in such analyses. In
SimTOST, no adjustments are made for trials involving more than two
treatment arms.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-chowdhry_finding_2024" class="csl-entry">
Chowdhry, Amit K., John Park, John Kang, Gukan Sakthivel, and Stephanie
Pugh. 2024. <span>“Finding <span>Multiple Signals</span> in the
<span>Noise</span>: <span>Handling Multiplicity</span> in <span>Clinical
Trials</span>.”</span> <em>International Journal of Radiation
Oncology*Biology*Physics</em> 119 (3): 750–55. <a href="https://doi.org/10.1016/j.ijrobp.2023.12.007">https://doi.org/10.1016/j.ijrobp.2023.12.007</a>.
</div>
<div id="ref-CHMP2010" class="csl-entry">
Committee for Medicinal Products for Human Use (CHMP). 2010.
<span>“Guideline on the Investigation of Bioequivalence.”</span>
CPMP/EWP/QWP/1401/98. London, UK: European Medicines Agency. <a href="https://www.ema.europa.eu/en/documents/scientific-guideline/guideline-investigation-bioequivalence-rev1_en.pdf">https://www.ema.europa.eu/en/documents/scientific-guideline/guideline-investigation-bioequivalence-rev1_en.pdf</a>.
</div>
<div id="ref-cpmp_points_2002" class="csl-entry">
Committee for Propietary Medicinal Products (CPMP). 2002. <span>“Points
to Consider on Multiplicity Issues in Clinical Trials.”</span>
Scientific Guideline CPMP/EWP/908/99. London, UK: The European Agency
for the Evaluation of Medicinal Products.
</div>
<div id="ref-mielke_sample_2018" class="csl-entry">
Mielke, Johanna, Byron Jones, Bernd Jilma, and Franz König. 2018.
<span>“Sample <span>Size</span> for <span>Multiple Hypothesis
Testing</span> in <span>Biosimilar Development</span>.”</span>
<em>Statistics in Biopharmaceutical Research</em> 10 (1): 39–49. <a href="https://doi.org/10.1080/19466315.2017.1371071">https://doi.org/10.1080/19466315.2017.1371071</a>.
</div>
<div id="ref-sozu_continuous_2015" class="csl-entry">
Sozu, Takashi, Tomoyuki Sugimoto, Toshimitsu Hamasaki, and Scott R.
Evans. 2015a. <span>“Continuous Primary Endpoints.”</span> In <em>Sample
Size Determination in Clinical Trials with Multiple Endpoints</em>,
59–68. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-22005-5_5">https://doi.org/10.1007/978-3-319-22005-5_5</a>.
</div>
<div id="ref-sozu_sample_2015" class="csl-entry">
———. 2015b. <em>Sample <span>Size Determination</span> in <span>Clinical
Trials</span> with <span>Multiple Endpoints</span></em>.
<span>SpringerBriefs</span> in <span>Statistics</span>. Cham: Springer
International Publishing. <a href="https://doi.org/10.1007/978-3-319-22005-5">https://doi.org/10.1007/978-3-319-22005-5</a>.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
